# ğŸ“º TV Program Web Scraper

An automated TV program scraping system with real-time viewer simulation and global API deployment.

## ğŸš€ Live Demo
- **Global API**: https://tv-scraper.tvdata.workers.dev
- **Local API**: http://localhost:5001 (when running locally)
- **Endpoints**: `/status`, `/now-playing`, `/viewers`

> ğŸ”„ **API Sync**: Both local and global APIs serve identical real TV data formats

## ğŸ¯ Project Overview

This project demonstrates a complete data pipeline from web scraping to global API deployment:

```
ğŸ•·ï¸ Scrapers â†’ ğŸ—„ï¸ Database â†’ ğŸ–¥ï¸ Local API â†’ ğŸŒ Global Deployment
```

### **Core Features:**
- âœ… **Automated scraping** of 3 TV channels (BBC Earth, Discovery, National Geographic)
- âœ… **SQLite database** with structured TV program data
- âœ… **Real-time viewer simulation** with realistic counts
- âœ… **Local development** environment with Docker
- âœ… **Global deployment** on Cloudflare Workers edge network
- âœ… **Scheduled automation** every 6 hours

## ğŸ› ï¸ Technology Stack

| Component | Technology |
|-----------|------------|
| **Scraping** | Python + BeautifulSoup |
| **Database** | SQLite |
| **Local API** | Flask |
| **Containerization** | Docker + Docker Compose |
| **Global API** | Cloudflare Workers (Serverless) |
| **Automation** | Python Schedule |
| **Deployment** | Git + Wrangler CLI |

## ğŸ“‚ Project Structure

```
tv-scraper/
â”œâ”€â”€ ğŸ•·ï¸ scrapers/
â”‚   â”œâ”€â”€ scraper_BBC.py          # BBC Earth scraper
â”‚   â”œâ”€â”€ scraper_Disc.py         # Discovery Channel scraper
â”‚   â””â”€â”€ scraper_NatGeo.py       # National Geographic scraper
â”œâ”€â”€ ğŸ—„ï¸ data/
â”‚   â”œâ”€â”€ tvguide.db              # SQLite database
â”‚   â”œâ”€â”€ tv_programs_BBC.txt     # Raw scraped data
â”‚   â”œâ”€â”€ tv_programs_Disc.txt
â”‚   â””â”€â”€ tv_programs_NatGeo.txt
â”œâ”€â”€ ğŸ–¥ï¸ local-api/
â”‚   â”œâ”€â”€ flask_now_playing.py    # Local Flask API server
â”‚   â”œâ”€â”€ load_tv_programs_sqlite.py # Database loader
â”‚   â””â”€â”€ scheduler.py            # Automated scraping scheduler
â”œâ”€â”€ ğŸŒ global-api/
â”‚   â”œâ”€â”€ worker.js               # Cloudflare Workers API
â”‚   â””â”€â”€ wrangler.toml           # Cloudflare configuration
â””â”€â”€ ğŸ³ deployment/
    â”œâ”€â”€ docker-compose.yml      # Local environment
    â”œâ”€â”€ Dockerfile              # Container definition
    â””â”€â”€ requirements.txt        # Python dependencies
```

## ğŸš€ Quick Start

### **Option 1: Local Development**
```bash
# Clone the repository
git clone https://github.com/sarontebebe7/tv-scraper.git
cd tv-scraper

# Start with Docker (recommended)
docker-compose up -d

# Access local API
curl http://localhost:5001/now-playing
```

### **Option 2: Use Global API**
```bash
# Already deployed and running!
curl https://tv-scraper.tvdata.workers.dev/now-playing
```

## ï¿½ API Synchronization

Both local and global APIs now serve **identical real TV data**:

| Environment | URL | Data Source |
|-------------|-----|-------------|
| **Local Development** | `http://localhost:5001` | Real scraped data from SQLite |
| **Global Production** | `https://tv-scraper.tvdata.workers.dev` | Real data (synchronized) |

### **Why This Matters for Teams:**
- âœ… **Consistent Integration**: Same JSON format across environments  
- âœ… **Real Data**: No demo/mock data - actual Slovak TV programming
- âœ… **Reliable Testing**: Develop locally, deploy globally with confidence
- âœ… **Live Data**: Current programs updated every 6 hours

## ï¿½ğŸ“Š API Endpoints

### **GET /status**
System health and configuration information
```json
{
  "service": "TV Program Scraper API",
  "status": "operational",
  "timestamp": "2025-11-06T10:15:00.000Z",
  "stats": {
    "database": "connected",
    "channels": ["BBC Earth", "Discovery Channel", "National Geographic"]
  }
}
```

### **GET /now-playing**  
Current TV programs across all channels (REAL DATA)
```json
[
  {
    "channel": "BBC Earth",
    "title": "Å½ivot, smrt a odkaz Tutanchamona 1",
    "start": "09:10:00",
    "date": "06.11.2025",
    "csfd_id": ""
  },
  {
    "channel": "Discovery Channel", 
    "title": "Lovci odpadu 12",
    "start": "09:00:00",
    "date": "06.11.2025",
    "csfd_id": ""
  }
]
```

### **GET /viewers**
Live viewer counts simulation
```json
[
  {
    "channel": "Discovery Channel",
    "viewers": "4185"
  },
  {
    "channel": "BBC Earth", 
    "viewers": "3925"
  },
  {
    "channel": "National Geographic",
    "viewers": "4431"
  }
]
  "success": true,
  "data": [
    {
      "channel": "BBC Earth",
      "viewers": "4,245",
      "trend": "â†—",
      "region_breakdown": {
        "North America": 1698,
        "Europe": 1486,
        "Asia": 637
      }
    }
  ]
}
```

## ğŸ”„ Automated Data Pipeline

The system automatically:

1. **Scrapes** TV program data every 6 hours
2. **Processes** and cleans the data
3. **Updates** SQLite database
4. **Logs** all operations with status monitoring
5. **Serves** data via both local and global APIs

```python
# Automation powered by scheduler.py
schedule.every(6).hours.do(run_all_scrapers)
schedule.every().day.at("06:00").do(run_all_scrapers)
```

## ğŸŒ Deployment Architecture

### **Local Environment:**
- **Docker Compose** for easy development
- **Flask API** with full database access
- **Complete feature set** for testing

### **Production Environment:**
- **Cloudflare Workers** for global edge deployment
- **Automatic scaling** and 99.9% uptime
- **Global CDN** for fast worldwide access

## ğŸ“ˆ Future Enhancements

- [ ] **Star Schema** implementation for advanced analytics
- [ ] **Real-time data streaming** with WebSockets
- [ ] **Machine learning** for viewer prediction
- [ ] **Multi-language support** for international channels
- [ ] **GraphQL API** for flexible data queries

## ğŸ¤ Contributing

This project demonstrates modern data engineering practices including:
- Web scraping at scale
- Database design and management
- API development and deployment
- Container orchestration
- Global edge computing
- Automated data pipelines

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) file for details

## ğŸ¯ About

Created as a demonstration of end-to-end data pipeline development, from web scraping to global API deployment using modern cloud infrastructure.

**Live API**: https://tv-scraper.tvdata.workers.dev